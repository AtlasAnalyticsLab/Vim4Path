configurations = {
    "vim-t": {
        "img_size": 224,
        "patch_size": 16,
        "stride": 16,
        "embed_dim": 192,
        "depth": 24,
        "rms_norm": True,
        "attn_drop_rate": 0.0,
        "drop_path_rate": 0.1,
        "residual_in_fp32": True,
        "fused_add_norm": True,
        "final_pool_type": "mean",
        "if_abs_pos_embed": True,
        "if_rope": False,
        "if_rope_residual": False,
        "if_cls_token": True,
        "if_devide_out": True,
        "use_middle_cls_token": True,
        "bimamba_type": "v2"
    },
    "vim-t-plus": {
        "img_size": 224,
        "patch_size": 16,
        "stride": 16,
        "embed_dim": 384,
        "depth": 12,
        "rms_norm": True,
        "attn_drop_rate": 0.0,
        "drop_path_rate": 0.1,
        "residual_in_fp32": True,
        "fused_add_norm": True,
        "final_pool_type": "mean",
        "if_abs_pos_embed": True,
        "if_rope": False,
        "if_rope_residual": False,
        "if_cls_token": True,
        "if_devide_out": True,
        "use_middle_cls_token": True,
        "bimamba_type": "v2"
    },
    "vim-s": {
        "img_size": 224,
        "patch_size": 16,
        "stride": 16,
        "embed_dim": 384,
        "depth": 24,
        "rms_norm": True,
        "attn_drop_rate": 0.0,
        "drop_path_rate": 0.1,
        "residual_in_fp32": True,
        "fused_add_norm": True,
        "final_pool_type": "mean",
        "if_abs_pos_embed": True,
        "if_rope": False,
        "if_rope_residual": False,
        "if_cls_token": True,
        "if_devide_out": True,
        "use_middle_cls_token": True,
        "bimamba_type": "v2"
    },
    "vit-t": {
        "img_size": 512,
        "patch_size": 16,
        "in_chans": 3,
        "num_classes": 2,
        "embed_dim": 192,
        "depth": 12,
        "num_heads": 3,
        "mlp_ratio": 4,
        "qkv_bias": True,
        "qk_scale": None,
        "drop_rate": 0.0,
        "attn_drop_rate": 0.0,
        "drop_path_rate": 0.1,
        "norm_layer": "nn.LayerNorm",
        "eps": 1e-6
    },
    "vit-s": {
        "img_size": 512,
        "patch_size": 16,
        "in_chans": 3,
        "num_classes": 2,
        "embed_dim": 384,
        "depth": 12,
        "num_heads": 6,
        "mlp_ratio": 4,
        "qkv_bias": True,
        "qk_scale": None,
        "drop_rate": 0.0,
        "attn_drop_rate": 0.0,
        "drop_path_rate": 0.1,
        "norm_layer": "nn.LayerNorm",
        "eps": 1e-6
    },
    "vmamba-t": {
            "patch_size": 4,
            "in_chans": 3,
            "num_classes": 2,
            "depths": [2, 2, 5, 2],
            "dims": 96,
            "ssm_d_state": 1,
            "ssm_ratio": 2.0,
            "ssm_rank_ratio": 2.0,
            "ssm_dt_rank": "auto",
            "ssm_act_layer": "silu",
            "ssm_conv": 3,
            "ssm_conv_bias": False,
            "ssm_drop_rate": 0.0,
            "ssm_init": "v0",
            "forward_type": "v05_noz",
            "mlp_ratio": 4.0,
            "mlp_act_layer": "gelu",
            "mlp_drop_rate": 0.0,
            "drop_path_rate": 0.2,
            "patch_norm": True,
            "norm_layer": "ln2d",
            "downsample_version": "v3",
            "patchembed_version": "v1",
            "gmlp": False,
            "use_checkpoint": False,
            "posembed": False,
            "imgsize": 224
        },
    "vmamba-s": {
        "patch_size": 16,
        "in_chans": 3,
        "num_classes": 2,
        "depths": [2, 2, 15, 2],
        "dims": 96,
        "ssm_d_state": 1,
        "ssm_ratio": 2.0,
        "ssm_rank_ratio": 2.0,
        "ssm_dt_rank": "auto",
        "ssm_act_layer": "silu",
        "ssm_conv": 3,
        "ssm_conv_bias": False,
        "ssm_drop_rate": 0.0,
        "ssm_init": "v0",
        "forward_type": "v05_noz",
        "mlp_ratio": 4.0,
        "mlp_act_layer": "gelu",
        "mlp_drop_rate": 0.0,
        "drop_path_rate": 0.3,
        "patch_norm": True,
        "norm_layer": "ln2d",
        "downsample_version": "v3",
        "patchembed_version": "v1",
        "gmlp": False,
        "use_checkpoint": False,
        "posembed": False,
        "imgsize": 224
    },
    "vmamba-b": {
        "patch_size": 16,
        "in_chans": 3,
        "num_classes": 2,
        "depths": [2, 2, 15, 2],
        "dims": 128,
        "ssm_d_state": 1,
        "ssm_ratio": 2.0,
        "ssm_rank_ratio": 2.0,
        "ssm_dt_rank": "auto",
        "ssm_act_layer": "silu",
        "ssm_conv": 3,
        "ssm_conv_bias": False,
        "ssm_drop_rate": 0.0,
        "ssm_init": "v0",
        "forward_type": "v05_noz",
        "mlp_ratio": 4.0,
        "mlp_act_layer": "gelu",
        "mlp_drop_rate": 0.0,
        "drop_path_rate": 0.6,
        "patch_norm": True,
        "norm_layer": "ln2d",
        "downsample_version": "v3",
        "patchembed_version": "v1",
        "gmlp": False,
        "use_checkpoint": False,
        "posembed": False,
        "imgsize": 224
    }
}